# -*- coding: utf-8 -*-
"""Data_Analysis_France_PR2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14X6BPeH3ZYbVO1lUYT8GC-laMqpwjzxS
"""

# This content was created as a supporting material for the textbook
# EXPLORATORY DATA ANALYSIS: Descriptive Analysis, Visualization and Dashboard Design (with codes in Python)
# authored by Leandro de Castro (c), 2023-2024
# All rights reserved, Distribution is not allowed without the author's formal consent

# Chapter 3 - Descriptive Analysis
# SUMMARY
# 0. Importing the Libraries and Loading the Chapter Data
# 1. Central Tendency and Dispersion Measures: One Variable at a Time
# 2. Central Tendency and Dispersion Measures: All Variables at Once
# 3. Association Measures
# 4. Analyzing Through Visualization
# Final challenge

!pip install researchpy

import statistics as st # Built in Python library for descriptive statistics
import pandas as pd  # Data manipulation and analysis library
import researchpy as rp  # Open source library focused on univariate and bivariate analysis
import numpy as np  # General purpose array processing package
import seaborn as sns  # Data visualization library based on matplotlib
import matplotlib.pyplot as plt  # Data visualization library
import scipy.stats as spy  # Statistical library from Scipy
import statistics as st # Built in Python library for descriptive statistics
import pandas as pd  # Data manipulation and analysis library
import researchpy as rp  # Open source library focused on univariate and bivariate analysis
import numpy as np  # General purpose array processing package
import seaborn as sns  # Data visualization library based on matplotlib
import matplotlib.pyplot as plt  # Data visualization library
import scipy.stats as spy  # Statistical library from Scipy
from scipy.stats import norm, kurtosis, laplace, semicircular
from scipy import stats
from scipy.stats import gmean, hmean, trim_mean

import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Load your data from the CSV file
# Replace 'insurance.csv' with the actual filename
df = pd.read_csv('insurance.csv')

# Filter data for men and women who smoke and don't smoke
smoking_men = df[(df['sex'] == 'male') & (df['smoker'] == 'yes')]
non_smoking_men = df[(df['sex'] == 'male') & (df['smoker'] == 'no')]

smoking_women = df[(df['sex'] == 'female') & (df['smoker'] == 'yes')]
non_smoking_women = df[(df['sex'] == 'female') & (df['smoker'] == 'no')]

# Create a 3D scatter plot
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot for smoking men
ax.scatter(smoking_men['age'], smoking_men['bmi'], smoking_men['charges'], label='Smoking Men', marker='o')

# Scatter plot for non-smoking men
ax.scatter(non_smoking_men['age'], non_smoking_men['bmi'], non_smoking_men['charges'], label='Non-Smoking Men', marker='^')

# Scatter plot for smoking women
ax.scatter(smoking_women['age'], smoking_women['bmi'], smoking_women['charges'], label='Smoking Women', marker='s')

# Scatter plot for non-smoking women
ax.scatter(non_smoking_women['age'], non_smoking_women['bmi'], non_smoking_women['charges'], label='Non-Smoking Women', marker='d')

# Customize the plot
ax.set_xlabel('Age')
ax.set_ylabel('BMI')
ax.set_zlabel('Charges')
ax.set_title('3D Scatter Plot: Medical Costs by Gender and Smoking Status')
ax.legend()

# Show the 3D scatter plot
plt.show()

import pandas as pd

# Read the first CSV file
df1 = pd.read_csv('file1.csv')

# Read the second CSV file
df2 = pd.read_csv('file2.csv')

# Assuming both files have a common column named 'ID'
# Merge the two DataFrames based on the 'ID' column
merged_df = pd.merge(df1, df2[['CODGEO', 'SNHM14', 'SNHMC14', 'SNHMP14',
                               'SNHME14', 'SNHMO14', 'SNHMF14', 'SNHMFC14',
                               'SNHMFP14', 'SNHMFE14', 'SNHMFO14', 'SNHMH14',
                               'SNHMHC14', 'SNHMHP14', 'SNHMHE14',
                               'SNHMHO14', 'SNHM1814', 'SNHM2614', 'SNHM5014',
                               'SNHMF1814', 'SNHMF2614', 'SNHMF5014', 'SNHMH1814',
                               'SNHMH2614', 'SNHMH5014']], on='CODGEO', how='left')

# Save the merged DataFrame to a new CSV file
merged_df.to_csv('combined_file.csv', index=False)

# Loading dataset1
# https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass
# Missing Values? Yes
dmammo = pd.read_csv('combined_file.csv')
dmammo.shape

dmammo.head

# Loading dataset1
# https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass
# Missing Values? Yes
dmammo = pd.read_csv('CO2 Emissions.csv')
dmammo.shape

# Loading dataset1
# https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass
# Missing Values? Yes
dmammo = pd.read_csv('file2.csv')
dmammo.shape

dmammo.head

# Determining the frequency distribution, frequency table and pie chart
# of variable 'Shape' in the Mammographic dataset

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Loading dataset1
# https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass
dmammo = pd.read_csv('insurance.csv')

SShape = pd.Series(dmammo['region'])
ftable = SShape.value_counts()  # Generate the frequency table
rftable = ftable/len(SShape)*100  # Relative frequency
cftable = ftable.cumsum()/len(SShape)*100  # Cumulative frequency
df = pd.DataFrame({'Frequency':ftable.to_list(),
                   'Relative Frequency':rftable.to_list(),
                  'Cumulative Frequency':cftable.to_list()})
print(df)
fig, figftable = plt.subplots()
figftable.pie(ftable.to_list(), labels=ftable.index.to_list(),
              autopct='%1.2f%%')  # From Matplotlib

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load your data from the CSV file
# Replace 'medical_bills.csv' with the actual filename
df = pd.read_csv('insurance.csv')

# Set the figure size
plt.figure(figsize=(5, 6))

# Create grouped bar chart
sns.barplot(x='sex', y='charges', data=df, ci=None, palette='pastel')

# Customize the chart
plt.title('Grouped Bar Chart of Medical Bill Charges by Gender')
plt.xlabel('sex')
plt.ylabel('charges')

# Display the chart
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load your data from the CSV file
# Replace 'medical_bills.csv' with the actual filename
df = pd.read_csv('insurance.csv')

# Set the figure size
plt.figure(figsize=(5, 6))

# Create grouped bar chart
sns.barplot(x='smoker', y='charges', data=df, ci=None, palette='pastel')

# Customize the chart
plt.title('Grouped Bar Chart of Medical Bill Charges by Gender')
plt.xlabel('smoker')
plt.ylabel('charges')

# Display the chart
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load your data from the CSV file
# Replace 'medical_bills.csv' with the actual filename
df = pd.read_csv('insurance.csv')

# Set the figure size
plt.figure(figsize=(5, 6))

# Create grouped bar chart
sns.barplot(x='smoker', y='bmi', data=df, ci=None, palette='pastel')

# Customize the chart
plt.title('Grouped Bar Chart of Medical Bill Charges by Gender')
plt.xlabel('sex')
plt.ylabel('charges')

# Display the chart
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load your data from the CSV file
# Replace 'data.csv' with the actual filename
df = pd.read_csv('insurance.csv')

# Create a violin plot
plt.figure(figsize=(10, 6))
sns.violinplot(x='charges', data=df, palette='viridis')

# Customize the plot
plt.title('Violin Plot: Frequency of Label')
plt.xlabel('Label')
plt.ylabel('Frequency')

# Show the violin plot
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load your data from the CSV file
# Replace 'your_data.csv' with the actual filename
df = pd.read_csv('insurance.csv')

# Extract the labels and values from the DataFrame
labels = df['sex']
values = df['bmi']

# Specify colors for each category
colors = plt.cm.viridis_r((values - min(values)) / (max(values) - min(values)))

# Create a doughnut chart
fig, ax = plt.subplots()
ax.pie(values, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors, wedgeprops=dict(width=0.3))

# Draw a white circle at the center to create a doughnut effect
centre_circle = plt.Circle((0, 0), 0.7, fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

# Equal aspect ratio ensures that the pie chart is drawn as a circle
ax.axis('equal')

# Display the chart
plt.title('Doughnut Chart from CSV Data')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load your data from the CSV file
# Replace 'your_data.csv' with the actual filename
df = pd.read_csv('file2.csv')

# Create a bubble chart using DataFrame columns
plt.scatter(df['X-axis'], df['Y-axis'], s=df['Size'], alpha=0.5)

# Customize the chart
plt.title('Bubble Chart from CSV Data')
plt.xlabel('X-axis')
plt.ylabel('Y-axis')

# Display the chart
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load your data from the CSV file
# Replace 'your_data.csv' with the actual filename
df = pd.read_csv('file2.csv')

# Set the figure size
plt.figure(figsize=(8, 6))

# Create a bar chart
plt.bar(df['bmi'], df['charges'], label='charges', color='blue', alpha=0.7)
plt.bar(df['bmi'], df['children'], label='children', color='green', alpha=0.7, bottom=df['SNHMHC14'])

# Customize the chart
plt.title('Bar Chart from CSV Data')
plt.xlabel('Categories')
plt.ylabel('Values')
plt.legend()

# Display the chart
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load your data from the CSV file
# Replace 'your_data.csv' with the actual filename
df = pd.read_csv('file1.csv')

# Extract the labels and values from the DataFrame
labels = df['DEP']
values = df['E14TST']

# Specify colors for each category
colors = plt.cm.viridis_r((values - min(values)) / (max(values) - min(values)))

# Create a doughnut chart
fig, ax = plt.subplots()
ax.pie(values, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors, wedgeprops=dict(width=0.3))

# Draw a white circle at the center to create a doughnut effect
centre_circle = plt.Circle((0, 0), 0.7, fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

# Equal aspect ratio ensures that the pie chart is drawn as a circle
ax.axis('equal')

# Display the chart
plt.title('Doughnut Chart from CSV Data')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load your data from the CSV file
# Replace 'your_data.csv' with the actual filename
df = pd.read_csv('file3.csv')

# Set the figure size
plt.figure(figsize=(20, 10))

# Create a bubble chart
plt.scatter(df['year'], df['state_abbr'], s=df['homicide'], alpha=0.5)

# Customize the chart
plt.title('Bubble Chart from CSV Data')
plt.xlabel('year')
plt.ylabel('violent_crime')

# Display the chart
plt.show()

# Determining the frequency distribution, frequency table and histogram
# of continuous variables in the Forest Fire dataset

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Loading dataset2
# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('file2.csv')

var = 'SNHM14'  # Choose the target variable
SShape = pd.Series(dforest[var])
nbins = 10
inflimit = 0; suplimit = max(SShape)
ampl = (suplimit - inflimit)/nbins

# Define the range of the variable and bin size
fbins = np.arange(0,suplimit+ampl,ampl)

# The pandas.cut function groups the data into bins and counts
# the frequency
ftable = pd.cut(SShape,fbins).value_counts() # Absolute frequency
rftable = ftable/len(SShape)*100  # Relative frequency
cftable = ftable.cumsum()/len(SShape)*100  # Cumulative frequency
df = pd.DataFrame({'Bins':ftable.index.to_list(),
                   'Frequency':ftable.to_list(),
                   'Relative Frequency':rftable.to_list(),
                   'Cumulative Frequency':cftable.to_list()})
print(df)
plt.xticks(fbins)
sns.histplot(dforest,x=var,bins=fbins, kde = 1)

# BONUS CODE
# Using Seaborn to determine the number of bins, bin width and the bin edges
# when auto is used for parameter bins in the histplot function

import pandas as pd
import seaborn as sns

dforest = pd.read_csv('file2.csv')
var = 'SNHM14'
ax = sns.histplot(dforest,x=var,bins='auto', kde = 2)
num_bins = len(ax.patches)
bin_width = (max(dforest[var])-min(dforest[var]))/num_bins
num_bins = len(ax.patches)
bin_edges = ax.get_xticks()
print(num_bins,bin_width,bin_edges)

# BONUS CODE
# Using Seaborn to determine the number of bins, bin width and the bin edges
# when auto is used for parameter bins in the histplot function

import pandas as pd
import seaborn as sns

dforest = pd.read_csv('insurance.csv')
var = 'charges'
ax = sns.histplot(dforest,x=var,bins='auto', kde = 2)
num_bins = len(ax.patches)
bin_width = (max(dforest[var])-min(dforest[var]))/num_bins
num_bins = len(ax.patches)
bin_edges = ax.get_xticks()
print(num_bins,bin_width,bin_edges)

pip install seaborn

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset (replace 'insurance.csv' with your actual file name)
df = pd.read_csv('insurance.csv')

# Filter the data for males
male_df = df[df['sex'] == 'male']

# Extract the BMI values for males
values = male_df['bmi']

# Create a colorful box plot using seaborn
sns.set(style="whitegrid")  # Set the style for the plot
plt.figure(figsize=(2, 8))  # Set the figure size

# Use the boxplot function from seaborn
sns.boxplot(y=values, color='green')

# Customize the plot
plt.title('BMI for Males')
plt.ylabel('BMI')

# Show the box plot
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset (replace 'insurance.csv' with your actual file name)
df = pd.read_csv('insurance.csv')

# Filter the data for males
male_df = df[df['sex'] == 'female']

# Extract the BMI values for males
values = male_df['bmi']

# Create a colorful box plot using seaborn
sns.set(style="whitegrid")  # Set the style for the plot
plt.figure(figsize=(2, 8))  # Set the figure size

# Use the boxplot function from seaborn
sns.boxplot(y=values, color='red')

# Customize the plot
plt.title('BMI for females')
plt.ylabel('BMI')

# Show the box plot
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset (replace 'data.csv' with your actual file name)
df = pd.read_csv('insurance.csv')

# Extract the column of interest
values = df['bmi']

# Create a colorful box plot using seaborn
sns.set(style="whitegrid")  # Set the style for the plot
plt.figure(figsize=(2, 8))  # Set the figure size

# Use the boxplot function from seaborn
sns.boxplot(y=values, color='orange')

# Customize the plot
plt.title('BMI')
plt.xlabel('Hourly Salary')

# Show the box plot
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset (replace 'insurance.csv' with your actual file name)
df = pd.read_csv('insurance.csv')

# Filter the data for males
male_df = df[df['smoker'] == 'yes']

# Extract the BMI values for males
values = male_df['bmi']

# Create a colorful box plot using seaborn
sns.set(style="whitegrid")  # Set the style for the plot
plt.figure(figsize=(2, 8))  # Set the figure size

# Use the boxplot function from seaborn
sns.boxplot(y=values, color='red')

# Customize the plot
plt.title('Smoker BMI')
plt.ylabel('BMI')

# Show the box plot
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset (replace 'insurance.csv' with your actual file name)
df = pd.read_csv('insurance.csv')

# Filter the data for males
male_df = df[df['smoker'] == 'no']

# Extract the BMI values for males
values = male_df['bmi']

# Create a colorful box plot using seaborn
sns.set(style="whitegrid")  # Set the style for the plot
plt.figure(figsize=(2, 8))  # Set the figure size

# Use the boxplot function from seaborn
sns.boxplot(y=values, color='blue')

# Customize the plot
plt.title('Non-Smoker BMI')
plt.ylabel('BMI')

# Show the box plot
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load your data from the CSV file
# Replace 'insurance.csv' with the actual filename
df = pd.read_csv('insurance.csv')

# Extract variables
age = df['children']
bmi = df['charges']

# Create a scatter plot
plt.scatter(age, bmi, color='green', alpha=0.7)

# Customize the chart
plt.title('Scatter Plot: children vs charges')
plt.xlabel('children')
plt.ylabel('charges')

# Show the scatter plot
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset (replace 'data.csv' with your actual file name)
df = pd.read_csv('file2.csv')

# Extract the column of interest
values = df['SNHMH14']

# Create a colorful box plot using seaborn
sns.set(style="whitegrid")  # Set the style for the plot
plt.figure(figsize=(2, 8))  # Set the figure size

# Use the boxplot function from seaborn
sns.boxplot(y=values, color='orange')

# Customize the plot
plt.title('Mean net salary for Men')
plt.xlabel('Hourly Salary')

# Show the box plot
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load your data from the CSV file
# Replace 'insurance.csv' with the actual filename
df = pd.read_csv('insurance.csv')

# Extract variables
x = df['age']
y = df['charges']
size = df['bmi']

# Create a bubble chart
plt.scatter(x, y, s=size, alpha=0.5, cmap='viridis', edgecolors='black')

# Customize the chart
plt.title('Bubble Chart: Age vs BMI vs Charges')
plt.xlabel('Age')
plt.ylabel('Charges')
plt.colorbar(label='BMI')

# Show the bubble chart
plt.show()

import geopandas as gpd
import matplotlib.pyplot as plt
import pandas as pd

# Load the shapefile for France's regions
france_shapefile = 'regions.shp'
map_df = gpd.read_file(france_shapefile)

# Load your data with a column indicating the number of employees
# Example data (replace this with your own data)
data = {'Region': ['Auvergne-Rhône-Alpes', 'Île-de-France', 'Provence-Alpes-Côte d\'Azur', 'Occitanie', 'Hauts-de-France'],
        'Employees': [3, 15, 80, 200, 550]}
business_data = pd.DataFrame(data)

# Merge the regional data with the shapefile
merged = map_df.set_index('nom').join(business_data.set_index('Region'))

# Create a choropleth map
fig, ax = plt.subplots(1, 1, figsize=(15, 10))
merged.plot(column='Employees', cmap='YlGnBu', linewidth=0.8, ax=ax, edgecolor='0.8', legend=True)

# Customize the plot
ax.set_title('Choropleth Map of France - Number of Employees in Businesses by Region')
ax.axis('off')

# Show the plot
plt.show()

# Plot distributions with different shapes
# Load the forest fires dataset from UCI

import seaborn as sns

dforest = pd.read_csv('CO2 Emissions.csv')

sns.histplot(dforest,x='Make',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Model',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Vehicle Class',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Engine Size(L)',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Cylinders',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Transmission',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Fuel Type',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Fuel Consumption City (L/100 km)',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Fuel Consumption Hwy (L/100 km)',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Fuel Consumption Comb (L/100 km)',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Fuel Consumption Comb (mpg)',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='CO2 Emissions(g/km)',bins='auto', kde = 2); plt.show()

# Generate Contingency Tables for the Mammographic Dataset

import pandas as pd

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data"
cols = ['BI-RADS', 'Age', 'Shape', 'Margin', 'Density', 'Severity']
dmammo = pd.read_csv(url, names=cols, na_values='?')

# Remove rows with missing values
dmammo.dropna(inplace=True)

# Print the contingency tables
var = ['Shape','Margin','Density']
print('**Contingency Tables**')
for i in var:
    CT = pd.crosstab(dmammo[i], dmammo['Severity'])
    print('Variables',i, 'and Severity:\n',CT)

"""# Central Tendency Measures"""

# Calculating the mean and mode one by one using the Statistics library
# Numeric variables

import statistics as st

# https://www.kaggle.com/datasets/bhuviranga/co2-emissions
dforest = pd.read_csv('CO2 Emissions.csv')

print('**CO2 Emissions Dataset**')
print('\n*Numeric Variable Engine Size(L)*')
print('Mean of variable Engine Size(L): {:.2f}'.format(st.mean(dforest['Engine Size(L)'])))
print('Median of variable Engine Size(L): {:.2f}'.format(st.median(dforest['Engine Size(L)'])))
midpoint = (max(dforest['Engine Size(L)'])+min(dforest['Engine Size(L)']))/2
print('Midpoint of variable Engine Size(L): {:.2f}'.format(midpoint))

print('\n*Numeric Variable Cylinders*')
print('Mean of variable Cylinders: {:.2f}'.format(st.mean(dforest['Cylinders'])))
print('Median of variable Cylinders: {:.2f}'.format(st.median(dforest['Cylinders'])))
midpoint = (max(dforest['Cylinders'])+min(dforest['Cylinders']))/2
print('Midpoint of variable Cylinders: {:.2f}'.format(midpoint))

print('\n*Numeric Variable Fuel Consumption City (L/100 km)*')
print('Mean of variable Fuel Consumption City (L/100 km): {:.2f}'.format(st.mean(dforest['Fuel Consumption City (L/100 km)'])))
print('Median of variable Fuel Consumption City (L/100 km): {:.2f}'.format(st.median(dforest['Fuel Consumption City (L/100 km)'])))
midpoint = (max(dforest['Fuel Consumption City (L/100 km)'])+min(dforest['Fuel Consumption City (L/100 km)']))/2
print('Midpoint of variable Fuel Consumption City (L/100 km): {:.2f}'.format(midpoint))

print('\n*Numeric Variable Fuel Consumption Hwy (L/100 km)*')
print('Mean of variable Fuel Consumption Hwy (L/100 km): {:.2f}'.format(st.mean(dforest['Fuel Consumption Hwy (L/100 km)'])))
print('Median of variable Fuel Consumption Hwy (L/100 km): {:.2f}'.format(st.median(dforest['Fuel Consumption Hwy (L/100 km)'])))
midpoint = (max(dforest['Fuel Consumption Hwy (L/100 km)'])+min(dforest['Fuel Consumption Hwy (L/100 km)']))/2
print('Midpoint of variable Fuel Consumption Hwy (L/100 km): {:.2f}'.format(midpoint))

print('\n*Numeric Variable Fuel Consumption Comb (L/100 km)*')
print('Mean of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(st.mean(dforest['Fuel Consumption Comb (L/100 km)'])))
print('Median of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(st.median(dforest['Fuel Consumption Comb (L/100 km)'])))
midpoint = (max(dforest['Fuel Consumption Comb (L/100 km)'])+min(dforest['Fuel Consumption Comb (L/100 km)']))/2
print('Midpoint of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(midpoint))

print('\n*Numeric Variable CO2 Emissions(g/km)*')
print('Mean of variable CO2 Emissions(g/km): {:.2f}'.format(st.mean(dforest['CO2 Emissions(g/km)'])))
print('Median of variable CO2 Emissions(g/km): {:.2f}'.format(st.median(dforest['CO2 Emissions(g/km)'])))
midpoint = (max(dforest['CO2 Emissions(g/km)'])+min(dforest['CO2 Emissions(g/km)']))/2
print('Midpoint of variable CO2 Emissions(g/km): {:.2f}'.format(midpoint))

# Nominal variables
print('\n*Categorical Variables*')
print('Mode of nominal variable Make: {v1}'
      .format(v1=st.mode(dforest['Make'])))
print('Mode of nominal variable Model: {v1}'
      .format(v1=st.mode(dforest['Model'])))
print('Mode of nominal variable Vehicle Class: {v1}'
      .format(v1=st.mode(dforest['Vehicle Class'])))
print('Mode of nominal variable Transmission: {v1}'
      .format(v1=st.mode(dforest['Transmission'])))

# Plot the central tendency measures over the histogram

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'CO2 Emissions(g/km)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

# Plot the central tendency measures over the histogram

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('insurance.csv')

var = 'charges'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Comb (mpg)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Comb (L/100 km)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Hwy (L/100 km)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption City (L/100 km)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Cylinders'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Engine Size(L)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()



# Calculate the weighted average (Eq. 3.5), geometric (Eq. 3.6)
# harmonic (Eq. 3.7), and trimmed (Eq. 3.8) means

import numpy as np
import scipy.stats as spy

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'CO2 Emissions(g/km)'
weights = np.random.randn(len(dforest[var]))
wavg = np.average(dforest[var], weights=weights)
gavg = spy.gmean(dforest[var])  # From Scipy library
havg = spy.hmean(dforest[var])  # From Scipy library
tavg = spy.trim_mean(dforest[var],0.05)  # 5% trim

print('Weighted average of variable CO2 Emissions(g/km): {:.2f}'.format(wavg))
print('Geometric mean of variable CO2 Emissions(g/km): {:.2f}'.format(gavg))
print('Harmonic mean of variable CO2 Emissions(g/km): {:.2f}'.format(havg))
print('Trimmed mean of variable CO2 Emissions(g/km): {:.2f}'.format(tavg))

var = 'Fuel Consumption Comb (L/100 km)'
weights = np.random.randn(len(dforest[var]))
wavg = np.average(dforest[var], weights=weights)
gavg = spy.gmean(dforest[var])  # From Scipy library
havg = spy.hmean(dforest[var])  # From Scipy library
tavg = spy.trim_mean(dforest[var],0.05)  # 5% trim

print('\nWeighted average of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(wavg))
print('Geometric mean of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(gavg))
print('Harmonic mean of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(havg))
print('Trimmed mean of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(tavg))

var = 'Fuel Consumption Comb (mpg)'
weights = np.random.randn(len(dforest[var]))
wavg = np.average(dforest[var], weights=weights)
gavg = spy.gmean(dforest[var])  # From Scipy library
havg = spy.hmean(dforest[var])  # From Scipy library
tavg = spy.trim_mean(dforest[var],0.05)  # 5% trim

print('Weighted average of variable Fuel Consumption Comb (mpg): {:.2f}'.format(wavg))
print('Geometric mean of variable Fuel Consumption Comb (mpg): {:.2f}'.format(gavg))
print('Harmonic mean of variable Fuel Consumption Comb (mpg): {:.2f}'.format(havg))
print('Trimmed mean of variable Fuel Consumption Comb (mpg): {:.2f}'.format(tavg))

"""# Comparing Central Tendency Measures

"""

# Central Tendency Measures for the Forest Fires Dataset
# Columns of interest: 'FFMC','DMC','DC', 'ISI', 'temp', 'RH', 'wind', 'rain'

import numpy as np
import scipy.stats as spy

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

ffmc = dforest['Fuel Consumption City (L/100 km)']; dmc = dforest['Fuel Consumption Hwy (L/100 km)']; dc = dforest['Fuel Consumption Comb (L/100 km)']
isi = dforest['Fuel Consumption Comb (mpg)']; temp = dforest['CO2 Emissions(g/km)']

# Dictionary to store the results
CTM = {}

# Loop over the columns and calculate the statistics
for col_name, col_data in zip(['Fuel Consumption City (L/100 km)','Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)'],
                              [ffmc, dmc, dc, isi, temp]):
    mean = np.mean(col_data)
    median = np.median(col_data)
    midpoint = (np.max(col_data) + np.min(col_data)) / 2
    gavg = spy.gmean(col_data)
    havg = spy.hmean(col_data)
    tavg = spy.trim_mean(col_data, proportiontocut=0.1)
    # Add the results to the dictionary
    CTM[col_name] = {'Mean': mean,
                         'Median': median,
                         'Midpoint': midpoint,
                         'Weighted Mean': wavg,
                         'Geometric Mean': gavg,
                         'Harmonic Mean': havg,
                         'Trimmed Mean': tavg}

# Print the results
for col_name, col_results in CTM.items():
    print(col_name)
    for stat_name, stat_value in col_results.items():
        print(f"\t{stat_name}: {stat_value:.2f}")

"""# Variability Measures"""

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'CO2 Emissions(g/km)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Variability Measures*')
print('Range of variable CO2 Emissions(g/km): {:.2f}'.format(drange))
print('IQR of variable CO2 Emissions(g/km): {:.2f}'.format(IQR))
print('sIQR of variable CO2 Emissions(g/km): {:.2f}'.format(sIQR))
print('Variance of variable CO2 Emissions(g/km): {:.2f}'.format(dvar))
print('Standard deviation of variable CO2 Emissions(g/km): {:.2f}'.format(dstd))
print('Variation coefficient of variable FFCO2 Emissions(g/km)MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Comb (mpg)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Fuel Consumption Comb (mpg) Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Comb (L/100 km)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Fuel Consumption Comb (L/100 km) Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Hwy (L/100 km)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Fuel Consumption Hwy (L/100 km) Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption City (L/100 km)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Fuel Consumption City (L/100 km) Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Engine Size(L)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Engine Size(L) Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Cylinders'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Cylinders Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'Fuel Consumption Comb (mpg)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'Fuel Consumption Comb (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'Fuel Consumption Hwy (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'Fuel Consumption City (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'Engine Size(L)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

"""# Measures of Shape"""

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Comb (mpg)'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Comb (mpg)'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Cylinders'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption City (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Hwy (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import kurtosis, norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)

# Determine kurtosis type
if kurtosis_value < 3:
    kurtosis_type = 'Platykurtic'
elif kurtosis_value > 3:
    kurtosis_type = 'Leptokurtic'
else:
    kurtosis_type = 'Mesokurtic (Normal)'

# Create a range of values spanning the distribution
x = data

# Create a plot for the distribution
plt.figure(figsize=(8, 6))
plt.hist(x, bins=30, density=True, alpha=0.7, color='blue', edgecolor='black', label=f'{column_name} Distribution')

# Plot a normal distribution for reference
mean, std_dev = x.mean(), x.std()
pdf = norm.pdf(x, mean, std_dev)
plt.plot(x, pdf, 'r', linewidth=2, label='Normal Distribution')

# Customize the plot
plt.title(f'{column_name} Distribution (Kurtosis Type: {kurtosis_type})')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

# Print the kurtosis value and type
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')
print(f'Kurtosis Type: {kurtosis_type}')

import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import kurtosis

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)

# Create a histogram plot for the kurtosis distribution
plt.figure(figsize=(8, 6))
plt.hist(data, bins=30, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Kurtosis Distribution for {column_name}\nKurtosis Value: {kurtosis_value:.2f}')
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import kurtosis

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')



# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Comb (mpg)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')


# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Comb (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')



# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Hwy (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')



# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption City (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')



# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Engine Size(L)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')

import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import kurtosis

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_values = kurtosis(data)

# Create a histogram plot for the kurtosis distribution
plt.figure(figsize=(10, 6))
plt.hist(kurtosis_values, bins=30, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel('Kurtosis')
plt.ylabel('Count')
plt.title(f'Kurtosis Distribution for {column_name}')

# Show the plot
plt.grid(True)
plt.show()

# Skewness and Skewed distributions
# Generate random data with a left-skewed distribution

import statistics as st
import numpy as np
from scipy.stats import skew
import seaborn as sns
import matplotlib.pyplot as plt

data_neg = np.random.beta(a=5, b=1, size=1000)  # Beta distribution
mean = st.mean(data_neg)
median = st.median(data_neg)
midpoint = (max(data_neg) + min(data_neg)) / 2  # Calculate the midpoint
print('Mean, median, and midpoint: {:.2f} {:.2f} {:.2f}'
      .format(mean, median, midpoint))
print('Skewness (Fischer-Pearson Coefficient): {:.2f}'
      .format(skew(data_neg)))
print('Skewness (First Skewness Coefficient): {:.2f}'
      .format((mean - midpoint) / np.std(data_neg)))
sns.histplot(data_neg, bins='auto', kde=2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend()
plt.show()

# Kurtosis: mesokurtic, platykurtic and leptokurtic distributions

import numpy as np
from scipy.stats import norm, laplace, semicircular
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as spy

# Normal distribution (Mesokurtic)
dnorm = norm.rvs(size=10000)
print(type(dnorm))
k = spy.kurtosis(dnorm)
print('Kurtosis: {:.2f}'.format(k))
sns.histplot(dnorm,bins='auto', kde = 2)
plt.title(f"Normal Distribution - Kurtosis: {k:.2f}")
plt.show()

# Uniform distribution (Platykurtic)
dunif = np.random.uniform(0.01, 0.10, 10000)
k = spy.kurtosis(dunif)
print('Kurtosis: {:.2f}'.format(k))
sns.histplot(dunif,bins='auto', kde = 2)
plt.title(f"Uniform Distribution - Kurtosis: {k:.2f}")
plt.show()

# Laplace distribution (Leptokurtic)
dlap = laplace.rvs(loc=0, scale=1, size=10000)
k = spy.kurtosis(dlap)
sns.histplot(dlap, bins='auto', kde = 2)
plt.title(f"Laplace Distribution - Kurtosis: {k:.2f}")
plt.show()

# Wigner semicircle distribution
dwigner = semicircular.rvs(size=10000)
k = spy.kurtosis(dwigner)
sns.histplot(dwigner, bins='auto', kde = 2)
plt.title(f"Wigner Semicircle Distribution - Kurtosis: {k:.2f}")
plt.show()

# Calculate the Skewness and Kurtosis for the Forest Fires variables

import pandas as pd

# load dataset
dforest = pd.read_csv("CO2 Emissions.csv")

# Skewness and kurtosis for each variable
skewness = dforest[['Fuel Consumption City (L/100 km)','Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)']].skew()
kurt = dforest[['Fuel Consumption City (L/100 km)','Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)']].kurtosis()

# Print the results and classify the kurtosis
for var in skewness.index:
    print(f"{var} Skewness: {skewness[var]:.2f}")
    if kurt[var] > 0:
        print(f"{var} Kurtosis: {kurt[var]:.2f} (Leptokurtic)")
    elif kurt[var] < 0:
        print(f"{var} Kurtosis: {kurt[var]:.2f} (Platykurtic)")
    else:
        print(f"{var} Kurtosis: {kurt[var]:.2f} (Mesokurtic)")

"""# The Normal Distribution"""

# Plot Normal Distributions

import numpy as np
import matplotlib.pyplot as plt

# Define an array of mean and standard deviation values
vmu = np.array([-1,0,1])
vsigma = np.array([.5,1,1.5])

# Create an array of x-values
x = np.linspace(-5,5,100)

# Loop through the mean and standard deviation values and plot the normal
# distributions
for mu,sigma in zip(vmu,vsigma):
    y = (1/(sigma*np.sqrt(2*np.pi))) * np.exp(-((x-mu)**2)/(2*sigma**2))
    plt.plot(x, y, label=f'μ={mu},σ={sigma}')

# Add a legend and axis labels
plt.legend()
plt.xlabel('x')
plt.ylabel('Probability density')
plt.title('Normal Distributions')
plt.show()

# Plot a Normal Distribution detaching σ = {-3,-2,-1,0,1,2,3}

import numpy as np
import matplotlib.pyplot as plt

# Define the range of x values (which correspond to z-scores)
x = np.linspace(-4, 4, 1000)

# Calculate the probability density function (PDF) for the normal
# distribution
y = (1 / (np.sqrt(2 * np.pi))) * np.exp(-(x ** 2) / 2)

# Set up the plot, plot the PDF and vertical lines
fig, vax = plt.subplots()
vax.plot(x, y)
std = 1; mean = 0

for i in range(-3, 4):
    vax.axvline(mean + i * std, color='r', linestyle='--')

# Add a legend and labels to the plot
vax.set_xlabel("x")
vax.set_ylabel("PDF")
vax.set_title("Normal Distribution with Standard Deviation Lines")
plt.show()

"""# Measures of Association"""

# Calculate and print the Covariance Matrix of the Forest Fires dataset

import pandas as pd

# Load the dataset
dforest = pd.read_csv('CO2 Emissions.csv')

# Select the desired numeric features
features = ['Fuel Consumption City (L/100 km)','Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)']

# Compute the covariance matrix and format to two decimal places
pd.options.display.float_format = '{:.2f}'.format
Mcov = dforest[features].cov()

# Print the covariance matrix
print(Mcov)

# Calculate Correlation Coefficients: PCC, SRCC and KRCC
# for the numerical variables of the Forest Fires dataset

import pandas as pd

# Read the data into a pandas dataframe
dforest = pd.read_csv("CO2 Emissions.csv")
pd.options.display.float_format = '{:.2f}'.format

# Calculate PCC, SRCC, KRCC
print('**CO2 Emissions Dataset: PCC, SRCC, KRCC**')
PCC = dforest.corr(method='pearson')
print('Pearson Correlation Coefficient (PCC)\n',PCC)
SRCC = dforest.corr(method='spearman')
print('\nSpearman Rank Correlation Coefficient (SRCC)\n',SRCC)
KRCC = dforest.corr(method='kendall')
print('\nKramers Rank Correlation Coefficient (KRCC)\n',KRCC)

# Calculate Correlation Coefficients: Chi-square, Cramer's V and Point Biserial
# for the categorical variables of the Mammographic dataset
import pandas as pd
from scipy import stats
from scipy.stats import pointbiserialr

# Read the data from URL into a pandas dataframe
dforest = pd.read_csv("CO2 Emissions.csv")
dforest.dropna(inplace=True)  # Remove rows with missing values

# Chi-square and Cramer's V
cvars = ['Fuel Consumption City (L/100 km)','Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)']
# Categorical variables
chis = pd.DataFrame()
phi = pd.DataFrame()
for var1 in cvars:
    for var2 in cvars:
        if var1 != var2:
            chi2, p, dof, ex = stats.chi2_contingency(pd.crosstab(dforest[var1], dforest[var2]))
            chis.loc[var1, var2] = chi2
            phi.loc[var1, var2] = np.sqrt(chi2 / (dforest.shape[0] * (min(ex.shape) - 1)))
print('\n**Mammographic Dataset: Chi-Square, Krammers V, PBCC**\n')
print('Chi-Square Correlation Coefficient (chi^2)\n',chis)
print('\nKramers V Correlation Coefficient (phi)\n',phi)

# Point Biserial Correlation between Age and Severity
PBCC, pval = stats.pointbiserialr(dforest['Fuel Consumption Comb (mpg)'], dforest['Fuel Type'])
print('\nPBCC between Age and Severity: {:.2f}'.format(PBCC))

# Scatter plots between pairs of variables from the Forest Fires dataset

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
dforest = pd.read_csv("CO2 Emissions.csv")

# Extract the relevant columns
cols = ['Make', 'Model', 'Vehicle Class', 'Engine Size(L)', 'Cylinders',
        'Transmission', 'Fuel Type', 'Fuel Consumption City (L/100 km)',
        'Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)',
        'Fuel Consumption Comb (mpg)','CO2 Emissions(g/km)']
dforest = dforest[cols]
df = dforest

# Generate the scatter plots
fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))
plt.subplots_adjust(wspace=0.4, hspace=0.4)
axs[0, 0].scatter(df['Engine Size(L)'], df['Fuel Consumption Comb (mpg)'], alpha=0.5)
axs[0, 0].set_xlabel('Engine Size(L)'); axs[0, 0].set_ylabel('Fuel Consumption Comb (mpg)')
axs[0, 0].set_title('PCC: {:.2f}'.format(df['Engine Size(L)'].corr(df['Fuel Consumption Comb (mpg)'], method='pearson')))

axs[0, 1].scatter(dforest['Engine Size(L)'], dforest['CO2 Emissions(g/km)'], alpha=0.5)
axs[0, 1].set_xlabel('Engine Size(L)'); axs[0, 1].set_ylabel('CO2 Emissions(g/km)')
axs[0, 1].set_title('PCC: {:.2f}'.format(df['Engine Size(L)'].corr(df['CO2 Emissions(g/km)'], method='pearson')))

axs[1, 0].scatter(dforest['Cylinders'], dforest['Fuel Consumption Comb (mpg)'], alpha=0.5)
axs[1, 0].set_xlabel('Cylinders'); axs[1, 0].set_ylabel('Fuel Consumption Comb (mpg)')
axs[1, 0].set_title('PCC: {:.2f}'.format(df['Cylinders'].corr(df['Fuel Consumption Comb (mpg)'], method='pearson')))

axs[1, 1].scatter(dforest['Cylinders'], dforest['CO2 Emissions(g/km)'], alpha=0.5)
axs[1, 1].set_xlabel('Cylinders'); axs[1, 1].set_ylabel('CO2 Emissions(g/km)')
axs[1, 1].set_title('PCC: {:.2f}'.format(df['Cylinders'].corr(df['CO2 Emissions(g/km)'], method='pearson')))

plt.show()

# Scatter plots between pairs of variables from the Forest Fires dataset

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
dforest = pd.read_csv("file2.csv")

# Extract the relevant columns
cols = ['SNHMC14', 'SNHMP14']
dforest = dforest[cols]
df = dforest

# Generate the scatter plots
fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))
plt.subplots_adjust(wspace=0.4, hspace=0.4)
axs[0, 0].scatter(df['SNHMC14'], df['SNHMP14'], alpha=0.5)
axs[0, 0].set_xlabel('SNHMC14'); axs[0, 0].set_ylabel('SNHMP14')
axs[0, 0].set_title('PCC: {:.2f}'.format(df['SNHMC14'].corr(df['SNHMP14'], method='pearson')))


plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load your data from the CSV file
# Replace 'your_data.csv' with the actual filename
df = pd.read_csv('file2.csv')

# Plotting the lines
plt.plot(df['Time'], df['Line1'], label='Line 1', marker='o')
plt.plot(df['Time'], df['Line2'], label='Line 2', marker='s')

# Customize the chart
plt.title('Line Graph for Two Lines')
plt.xlabel('Time')
plt.ylabel('Values')
plt.legend()  # Display legend for line labels

# Display the chart
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load data from the first CSV file
df1 = pd.read_csv('file1.csv')

# Load data from the second CSV file
df2 = pd.read_csv('file2.csv')

# Create scatter plot
plt.scatter(df1['X'], df1['Y'], label='File 1', color='blue')
plt.scatter(df2['X'], df2['Y'], label='File 2', color='red')

# Customize the chart
plt.title('Scatter Plot of Two Columns from Different Files')
plt.xlabel('X-axis')
plt.ylabel('Y-axis')
plt.legend()

# Display the chart
plt.show()



# Scatter plots between pairs of variables from the Forest Fires dataset

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
dforest = pd.read_csv("CO2 Emissions.csv")

# Extract the relevant columns
cols = ['Make', 'Model', 'Vehicle Class', 'Engine Size(L)', 'Cylinders',
        'Transmission', 'Fuel Type', 'Fuel Consumption City (L/100 km)',
        'Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)',
        'Fuel Consumption Comb (mpg)','CO2 Emissions(g/km)']
dforest = dforest[cols]
df = dforest

# Generate the scatter plots
fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))
plt.subplots_adjust(wspace=0.4, hspace=0.4)
axs[0, 0].scatter(df['Engine Size(L)'], df['Fuel Consumption City (L/100 km)'], alpha=0.5)
axs[0, 0].set_xlabel('Engine Size(L)'); axs[0, 0].set_ylabel('Fuel Consumption City (L/100 km)')
axs[0, 0].set_title('PCC: {:.2f}'.format(df['Engine Size(L)'].corr(df['Fuel Consumption City (L/100 km)'], method='pearson')))

axs[0, 1].scatter(df['Engine Size(L)'], df['Fuel Consumption Hwy (L/100 km)'], alpha=0.5)
axs[0, 1].set_xlabel('Engine Size(L)'); axs[0, 1].set_ylabel('Fuel Consumption Hwy (L/100 km)')
axs[0, 1].set_title('PCC: {:.2f}'.format(df['Engine Size(L)'].corr(df['Fuel Consumption Hwy (L/100 km)'], method='pearson')))

axs[1, 0].scatter(dforest['Cylinders'], dforest['Fuel Consumption City (L/100 km)'], alpha=0.5)
axs[1, 0].set_xlabel('Cylinders'); axs[1, 0].set_ylabel('Fuel Consumption City (L/100 km)')
axs[1, 0].set_title('PCC: {:.2f}'.format(df['Cylinders'].corr(df['Fuel Consumption City (L/100 km)'], method='pearson')))

axs[1, 1].scatter(dforest['Cylinders'], dforest['Fuel Consumption Hwy (L/100 km)'], alpha=0.5)
axs[1, 1].set_xlabel('Cylinders'); axs[1, 1].set_ylabel('Fuel Consumption Hwy (L/100 km)')
axs[1, 1].set_title('PCC: {:.2f}'.format(df['Cylinders'].corr(df['Fuel Consumption Hwy (L/100 km)'], method='pearson')))

plt.show()