# -*- coding: utf-8 -*-
"""Obesity_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xNIDESOi1KcuuN3XKDm9ibVyaBkV-mlp
"""

# This content was created as a supporting material for the textbook
# EXPLORATORY DATA ANALYSIS: Descriptive Analysis, Visualization and Dashboard Design (with codes in Python)
# authored by Leandro de Castro (c), 2023-2024
# All rights reserved, Distribution is not allowed without the author's formal consent

# Chapter 3 - Descriptive Analysis
# SUMMARY
# 0. Importing the Libraries and Loading the Chapter Data
# 1. Central Tendency and Dispersion Measures: One Variable at a Time
# 2. Central Tendency and Dispersion Measures: All Variables at Once
# 3. Association Measures
# 4. Analyzing Through Visualization
# Final challenge

!pip install researchpy

import statistics as st # Built in Python library for descriptive statistics
import pandas as pd  # Data manipulation and analysis library
import researchpy as rp  # Open source library focused on univariate and bivariate analysis
import numpy as np  # General purpose array processing package
import seaborn as sns  # Data visualization library based on matplotlib
import matplotlib.pyplot as plt  # Data visualization library
import scipy.stats as spy  # Statistical library from Scipy
import statistics as st # Built in Python library for descriptive statistics
import pandas as pd  # Data manipulation and analysis library
import researchpy as rp  # Open source library focused on univariate and bivariate analysis
import numpy as np  # General purpose array processing package
import seaborn as sns  # Data visualization library based on matplotlib
import matplotlib.pyplot as plt  # Data visualization library
import scipy.stats as spy  # Statistical library from Scipy
from scipy.stats import norm, kurtosis, laplace, semicircular
from scipy import stats
from scipy.stats import gmean, hmean, trim_mean

# Loading dataset1
# https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass
# Missing Values? Yes
dmammo = pd.read_csv('CO2 Emissions.csv')
dmammo.shape

dmammo.head

import pandas as pd
import matplotlib.pyplot as plt

# Load the CSV file
df = pd.read_csv('CO2 Emissions.csv')

# Extract the two labels
label1 = df['FAF']
label2 = df['NObeyesdad']

# Create a scatter plot
plt.scatter(label1, label2, alpha=0.5)  # 'alpha' parameter controls transparency
plt.title('Scatter Plot between Label1 and Label2')
plt.xlabel('Exersize')
plt.ylabel('OB lvl')
plt.grid(True)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the CSV file
df = pd.read_csv('CO2 Emissions.csv')

# Extract the two labels
label1 = df['Age']
label2 = df['NObeyesdad']

# Create a scatter plot
plt.scatter(label1, label2, alpha=0.5)  # 'alpha' parameter controls transparency
plt.title('Scatter Plot between ')
plt.xlabel('Age')
plt.ylabel('OB lvl')
plt.grid(True)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset (replace 'data.csv' with your actual file name)
df = pd.read_csv('CO2 Emissions.csv')

# Extract relevant columns
x_values = df['SMOKE']
y_values = df['Age']
sizes = df['FCVC']
labels = df['FAF']

# Create a scatter plot with bubble sizes
plt.scatter(x_values, y_values, s=sizes*10, c=labels.map({'Label1': 'red', 'Label2': 'blue', 'Label3': 'green'}), alpha=0.7)

# Customize the plot
plt.title('Bubble Chart with Three Labels')
plt.xlabel('X-axis')
plt.ylabel('Y-axis')
plt.grid(True)
plt.legend(labels.unique(), title='Labels')
plt.show()

# Determining the frequency distribution, frequency table and pie chart
# of variable 'Shape' in the Mammographic dataset

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Loading dataset1
# https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass
dmammo = pd.read_csv('CO2 Emissions.csv')

SShape = pd.Series(dmammo['Vehicle Class'])
ftable = SShape.value_counts()  # Generate the frequency table
rftable = ftable/len(SShape)*100  # Relative frequency
cftable = ftable.cumsum()/len(SShape)*100  # Cumulative frequency
df = pd.DataFrame({'Frequency':ftable.to_list(),
                   'Relative Frequency':rftable.to_list(),
                  'Cumulative Frequency':cftable.to_list()})
print(df)
fig, figftable = plt.subplots()
figftable.pie(ftable.to_list(), labels=ftable.index.to_list(),
              autopct='%1.2f%%')  # From Matplotlib

# Determining the frequency distribution, frequency table and histogram
# of continuous variables in the Forest Fire dataset

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Loading dataset2
# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'FAF'  # Choose the target variable
SShape = pd.Series(dforest[var])
nbins = 10
inflimit = 0; suplimit = max(SShape)
ampl = (suplimit - inflimit)/nbins

# Define the range of the variable and bin size
fbins = np.arange(0,suplimit+ampl,ampl)

# The pandas.cut function groups the data into bins and counts
# the frequency
ftable = pd.cut(SShape,fbins).value_counts() # Absolute frequency
rftable = ftable/len(SShape)*100  # Relative frequency
cftable = ftable.cumsum()/len(SShape)*100  # Cumulative frequency
df = pd.DataFrame({'Bins':ftable.index.to_list(),
                   'Frequency':ftable.to_list(),
                   'Relative Frequency':rftable.to_list(),
                   'Cumulative Frequency':cftable.to_list()})
print(df)
plt.xticks(fbins)
sns.histplot(dforest,x=var,bins=fbins, kde = 2)

# BONUS CODE
# Using Seaborn to determine the number of bins, bin width and the bin edges
# when auto is used for parameter bins in the histplot function

import pandas as pd
import seaborn as sns

dforest = pd.read_csv('CO2 Emissions.csv')
var = 'CO2 Emissions(g/km)'
ax = sns.histplot(dforest,x=var,bins='auto', kde = 2)
num_bins = len(ax.patches)
bin_width = (max(dforest[var])-min(dforest[var]))/num_bins
num_bins = len(ax.patches)
bin_edges = ax.get_xticks()
print(num_bins,bin_width,bin_edges)

# Plot distributions with different shapes
# Load the forest fires dataset from UCI

import seaborn as sns

dforest = pd.read_csv('CO2 Emissions.csv')

sns.histplot(dforest,x='Make',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Model',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Vehicle Class',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Engine Size(L)',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Cylinders',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Transmission',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Fuel Type',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Fuel Consumption City (L/100 km)',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Fuel Consumption Hwy (L/100 km)',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Fuel Consumption Comb (L/100 km)',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='Fuel Consumption Comb (mpg)',bins='auto', kde = 2); plt.show()
sns.histplot(dforest,x='CO2 Emissions(g/km)',bins='auto', kde = 2); plt.show()

# Generate Contingency Tables for the Mammographic Dataset

import pandas as pd

url = "https://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data"
cols = ['BI-RADS', 'Age', 'Shape', 'Margin', 'Density', 'Severity']
dmammo = pd.read_csv(url, names=cols, na_values='?')

# Remove rows with missing values
dmammo.dropna(inplace=True)

# Print the contingency tables
var = ['Shape','Margin','Density']
print('**Contingency Tables**')
for i in var:
    CT = pd.crosstab(dmammo[i], dmammo['Severity'])
    print('Variables',i, 'and Severity:\n',CT)

"""# Central Tendency Measures"""

# Calculating the mean and mode one by one using the Statistics library
# Numeric variables

import statistics as st

# https://www.kaggle.com/datasets/bhuviranga/co2-emissions
dforest = pd.read_csv('CO2 Emissions.csv')

print('**CO2 Emissions Dataset**')
print('\n*Numeric Variable Engine Size(L)*')
print('Mean of variable Engine Size(L): {:.2f}'.format(st.mean(dforest['Engine Size(L)'])))
print('Median of variable Engine Size(L): {:.2f}'.format(st.median(dforest['Engine Size(L)'])))
midpoint = (max(dforest['Engine Size(L)'])+min(dforest['Engine Size(L)']))/2
print('Midpoint of variable Engine Size(L): {:.2f}'.format(midpoint))

print('\n*Numeric Variable Cylinders*')
print('Mean of variable Cylinders: {:.2f}'.format(st.mean(dforest['Cylinders'])))
print('Median of variable Cylinders: {:.2f}'.format(st.median(dforest['Cylinders'])))
midpoint = (max(dforest['Cylinders'])+min(dforest['Cylinders']))/2
print('Midpoint of variable Cylinders: {:.2f}'.format(midpoint))

print('\n*Numeric Variable Fuel Consumption City (L/100 km)*')
print('Mean of variable Fuel Consumption City (L/100 km): {:.2f}'.format(st.mean(dforest['Fuel Consumption City (L/100 km)'])))
print('Median of variable Fuel Consumption City (L/100 km): {:.2f}'.format(st.median(dforest['Fuel Consumption City (L/100 km)'])))
midpoint = (max(dforest['Fuel Consumption City (L/100 km)'])+min(dforest['Fuel Consumption City (L/100 km)']))/2
print('Midpoint of variable Fuel Consumption City (L/100 km): {:.2f}'.format(midpoint))

print('\n*Numeric Variable Fuel Consumption Hwy (L/100 km)*')
print('Mean of variable Fuel Consumption Hwy (L/100 km): {:.2f}'.format(st.mean(dforest['Fuel Consumption Hwy (L/100 km)'])))
print('Median of variable Fuel Consumption Hwy (L/100 km): {:.2f}'.format(st.median(dforest['Fuel Consumption Hwy (L/100 km)'])))
midpoint = (max(dforest['Fuel Consumption Hwy (L/100 km)'])+min(dforest['Fuel Consumption Hwy (L/100 km)']))/2
print('Midpoint of variable Fuel Consumption Hwy (L/100 km): {:.2f}'.format(midpoint))

print('\n*Numeric Variable Fuel Consumption Comb (L/100 km)*')
print('Mean of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(st.mean(dforest['Fuel Consumption Comb (L/100 km)'])))
print('Median of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(st.median(dforest['Fuel Consumption Comb (L/100 km)'])))
midpoint = (max(dforest['Fuel Consumption Comb (L/100 km)'])+min(dforest['Fuel Consumption Comb (L/100 km)']))/2
print('Midpoint of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(midpoint))

print('\n*Numeric Variable CO2 Emissions(g/km)*')
print('Mean of variable CO2 Emissions(g/km): {:.2f}'.format(st.mean(dforest['CO2 Emissions(g/km)'])))
print('Median of variable CO2 Emissions(g/km): {:.2f}'.format(st.median(dforest['CO2 Emissions(g/km)'])))
midpoint = (max(dforest['CO2 Emissions(g/km)'])+min(dforest['CO2 Emissions(g/km)']))/2
print('Midpoint of variable CO2 Emissions(g/km): {:.2f}'.format(midpoint))

# Nominal variables
print('\n*Categorical Variables*')
print('Mode of nominal variable Make: {v1}'
      .format(v1=st.mode(dforest['Make'])))
print('Mode of nominal variable Model: {v1}'
      .format(v1=st.mode(dforest['Model'])))
print('Mode of nominal variable Vehicle Class: {v1}'
      .format(v1=st.mode(dforest['Vehicle Class'])))
print('Mode of nominal variable Transmission: {v1}'
      .format(v1=st.mode(dforest['Transmission'])))

# Plot the central tendency measures over the histogram

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'CO2 Emissions(g/km)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Comb (mpg)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Comb (L/100 km)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Hwy (L/100 km)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption City (L/100 km)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Cylinders'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()

import statistics as st
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Engine Size(L)'  # Choose the target variable
mean = st.mean(dforest[var])
median = st.median(dforest[var])
midpoint = (max(dforest[var])+min(dforest[var]))/2
print('Mean, median and midpoint for CO2 Emissions:',mean,median,midpoint)
sns.histplot(dforest,x=var,bins='auto', kde = 2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend() # Add a legend
plt.show()



# Calculate the weighted average (Eq. 3.5), geometric (Eq. 3.6)
# harmonic (Eq. 3.7), and trimmed (Eq. 3.8) means

import numpy as np
import scipy.stats as spy

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'CO2 Emissions(g/km)'
weights = np.random.randn(len(dforest[var]))
wavg = np.average(dforest[var], weights=weights)
gavg = spy.gmean(dforest[var])  # From Scipy library
havg = spy.hmean(dforest[var])  # From Scipy library
tavg = spy.trim_mean(dforest[var],0.05)  # 5% trim

print('Weighted average of variable CO2 Emissions(g/km): {:.2f}'.format(wavg))
print('Geometric mean of variable CO2 Emissions(g/km): {:.2f}'.format(gavg))
print('Harmonic mean of variable CO2 Emissions(g/km): {:.2f}'.format(havg))
print('Trimmed mean of variable CO2 Emissions(g/km): {:.2f}'.format(tavg))

var = 'Fuel Consumption Comb (L/100 km)'
weights = np.random.randn(len(dforest[var]))
wavg = np.average(dforest[var], weights=weights)
gavg = spy.gmean(dforest[var])  # From Scipy library
havg = spy.hmean(dforest[var])  # From Scipy library
tavg = spy.trim_mean(dforest[var],0.05)  # 5% trim

print('\nWeighted average of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(wavg))
print('Geometric mean of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(gavg))
print('Harmonic mean of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(havg))
print('Trimmed mean of variable Fuel Consumption Comb (L/100 km): {:.2f}'.format(tavg))

var = 'Fuel Consumption Comb (mpg)'
weights = np.random.randn(len(dforest[var]))
wavg = np.average(dforest[var], weights=weights)
gavg = spy.gmean(dforest[var])  # From Scipy library
havg = spy.hmean(dforest[var])  # From Scipy library
tavg = spy.trim_mean(dforest[var],0.05)  # 5% trim

print('Weighted average of variable Fuel Consumption Comb (mpg): {:.2f}'.format(wavg))
print('Geometric mean of variable Fuel Consumption Comb (mpg): {:.2f}'.format(gavg))
print('Harmonic mean of variable Fuel Consumption Comb (mpg): {:.2f}'.format(havg))
print('Trimmed mean of variable Fuel Consumption Comb (mpg): {:.2f}'.format(tavg))

"""# Comparing Central Tendency Measures

"""

# Central Tendency Measures for the Forest Fires Dataset
# Columns of interest: 'FFMC','DMC','DC', 'ISI', 'temp', 'RH', 'wind', 'rain'

import numpy as np
import scipy.stats as spy

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

ffmc = dforest['Fuel Consumption City (L/100 km)']; dmc = dforest['Fuel Consumption Hwy (L/100 km)']; dc = dforest['Fuel Consumption Comb (L/100 km)']
isi = dforest['Fuel Consumption Comb (mpg)']; temp = dforest['CO2 Emissions(g/km)']

# Dictionary to store the results
CTM = {}

# Loop over the columns and calculate the statistics
for col_name, col_data in zip(['Fuel Consumption City (L/100 km)','Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)'],
                              [ffmc, dmc, dc, isi, temp]):
    mean = np.mean(col_data)
    median = np.median(col_data)
    midpoint = (np.max(col_data) + np.min(col_data)) / 2
    gavg = spy.gmean(col_data)
    havg = spy.hmean(col_data)
    tavg = spy.trim_mean(col_data, proportiontocut=0.1)
    # Add the results to the dictionary
    CTM[col_name] = {'Mean': mean,
                         'Median': median,
                         'Midpoint': midpoint,
                         'Weighted Mean': wavg,
                         'Geometric Mean': gavg,
                         'Harmonic Mean': havg,
                         'Trimmed Mean': tavg}

# Print the results
for col_name, col_results in CTM.items():
    print(col_name)
    for stat_name, stat_value in col_results.items():
        print(f"\t{stat_name}: {stat_value:.2f}")

"""# Variability Measures"""

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'CO2 Emissions(g/km)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Variability Measures*')
print('Range of variable CO2 Emissions(g/km): {:.2f}'.format(drange))
print('IQR of variable CO2 Emissions(g/km): {:.2f}'.format(IQR))
print('sIQR of variable CO2 Emissions(g/km): {:.2f}'.format(sIQR))
print('Variance of variable CO2 Emissions(g/km): {:.2f}'.format(dvar))
print('Standard deviation of variable CO2 Emissions(g/km): {:.2f}'.format(dstd))
print('Variation coefficient of variable FFCO2 Emissions(g/km)MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Comb (mpg)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Fuel Consumption Comb (mpg) Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Comb (L/100 km)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Fuel Consumption Comb (L/100 km) Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption Hwy (L/100 km)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Fuel Consumption Hwy (L/100 km) Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Fuel Consumption City (L/100 km)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Fuel Consumption City (L/100 km) Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Engine Size(L)'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Engine Size(L) Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

# Calculate the variability measures range (Eq. 3.9),
# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12),
# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy

import numpy as np

# https://archive.ics.uci.edu/ml/datasets/forest+fires
dforest = pd.read_csv('CO2 Emissions.csv')

var = 'Cylinders'
drange = np.max(dforest[var]) - np.min(dforest[var])
Q1, Q3 = np.percentile(dforest[var], [25,75])
IQR = Q3 - Q1
sIQR = IQR / 2
dvar = np.var(dforest[var])
dstd = np.std(dforest[var])
CV = dstd / np.mean(dforest[var]) * 100

print('*Cylinders Variability Measures*')
print('Range of variable : {:.2f}'.format(drange))
print('IQR of variable : {:.2f}'.format(IQR))
print('sIQR of variable : {:.2f}'.format(sIQR))
print('Variance of variable : {:.2f}'.format(dvar))
print('Standard deviation of variable : {:.2f}'.format(dstd))
print('Variation coefficient of variable MC: {:.2f}'.format(CV))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'Fuel Consumption Comb (mpg)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'Fuel Consumption Comb (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'Fuel Consumption Hwy (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'Fuel Consumption City (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to plot
column_name = 'Engine Size(L)'

# Extract the column data
data = df[column_name]

# Calculate mean and standard deviation
mean = data.mean()
std_dev = data.std()

# Create a range of values spanning the distribution
x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)

# Calculate the PDF values using the normal distribution
pdf = norm.pdf(x, mean, std_dev)

# Create a plot for the normal distribution
plt.figure(figsize=(8, 6))
plt.plot(x, pdf, label='Normal Distribution')
plt.fill_between(x, pdf, 0, alpha=0.2, color='blue')

# Plot standard deviation lines
plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(mean + std_dev, color='green', linestyle='dashed', linewidth=2, label=f'Standard Deviation: {std_dev:.2f}')
plt.axvline(mean - std_dev, color='green', linestyle='dashed', linewidth=2)

# Customize the plot
plt.title(f'Normal Distribution for {column_name}')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

"""# Measures of Shape"""

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Comb (mpg)'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Comb (mpg)'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Cylinders'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption City (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

# Skewness and Skewed distributions

import pandas as pd
import scipy.stats as stats

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Hwy (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate the skewness of the column
skewness = stats.skew(data)

# Calculate the Fisher-Pearson Coefficient
fisher_pearson_coeff = skewness / stats.sem(data)

# Calculate the First Skewness Coefficient (B1)
n = len(data)
b1 = (sum((data - data.mean()) ** 3) / n) / (data.std() ** 3)

# Determine if the distribution is skewed
if skewness > 0:
    skewness_result = f"The distribution of '{column_name}' is positively skewed."
elif skewness < 0:
    skewness_result = f"The distribution of '{column_name}' is negatively skewed."
else:
    skewness_result = f"The distribution of '{column_name}' is approximately symmetric."

# Create a histogram plot
plt.figure(figsize=(8, 6))
plt.hist(data, bins=20, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Histogram of {column_name}')
plt.axvline(data.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {data.mean():.2f}')
plt.axvline(data.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {data.median():.2f}')
plt.legend()
plt.show()

# Print the skewness, Fisher-Pearson Coefficient, First Skewness Coefficient, and result
print(f"Skewness value for '{column_name}': {skewness}")
print(f"Fisher-Pearson Coefficient: {fisher_pearson_coeff}")
print(f"First Skewness Coefficient (B1): {b1}")
print(skewness_result)

import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import kurtosis, norm

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)

# Determine kurtosis type
if kurtosis_value < 3:
    kurtosis_type = 'Platykurtic'
elif kurtosis_value > 3:
    kurtosis_type = 'Leptokurtic'
else:
    kurtosis_type = 'Mesokurtic (Normal)'

# Create a range of values spanning the distribution
x = data

# Create a plot for the distribution
plt.figure(figsize=(8, 6))
plt.hist(x, bins=30, density=True, alpha=0.7, color='blue', edgecolor='black', label=f'{column_name} Distribution')

# Plot a normal distribution for reference
mean, std_dev = x.mean(), x.std()
pdf = norm.pdf(x, mean, std_dev)
plt.plot(x, pdf, 'r', linewidth=2, label='Normal Distribution')

# Customize the plot
plt.title(f'{column_name} Distribution (Kurtosis Type: {kurtosis_type})')
plt.xlabel(column_name)
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()

# Print the kurtosis value and type
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')
print(f'Kurtosis Type: {kurtosis_type}')

import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import kurtosis

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)

# Create a histogram plot for the kurtosis distribution
plt.figure(figsize=(8, 6))
plt.hist(data, bins=30, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel(column_name)
plt.ylabel('Frequency')
plt.title(f'Kurtosis Distribution for {column_name}\nKurtosis Value: {kurtosis_value:.2f}')
plt.grid(True)

# Show the plot
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import kurtosis

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')



# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Comb (mpg)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')


# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Comb (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')



# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption Hwy (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')



# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Fuel Consumption City (L/100 km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')



# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'Engine Size(L)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_value = kurtosis(data)
print(f'Kurtosis value for {column_name}: {kurtosis_value:.2f}')

import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import kurtosis

# Load the CSV file into a pandas DataFrame
df = pd.read_csv('CO2 Emissions.csv')

# Replace 'your_column_name' with the name of the column you want to analyze
column_name = 'CO2 Emissions(g/km)'

# Extract the column data
data = df[column_name]

# Calculate kurtosis
kurtosis_values = kurtosis(data)

# Create a histogram plot for the kurtosis distribution
plt.figure(figsize=(10, 6))
plt.hist(kurtosis_values, bins=30, color='blue', alpha=0.7, edgecolor='black')
plt.xlabel('Kurtosis')
plt.ylabel('Count')
plt.title(f'Kurtosis Distribution for {column_name}')

# Show the plot
plt.grid(True)
plt.show()

# Skewness and Skewed distributions
# Generate random data with a left-skewed distribution

import statistics as st
import numpy as np
from scipy.stats import skew
import seaborn as sns
import matplotlib.pyplot as plt

data_neg = np.random.beta(a=5, b=1, size=1000)  # Beta distribution
mean = st.mean(data_neg)
median = st.median(data_neg)
midpoint = (max(data_neg) + min(data_neg)) / 2  # Calculate the midpoint
print('Mean, median, and midpoint: {:.2f} {:.2f} {:.2f}'
      .format(mean, median, midpoint))
print('Skewness (Fischer-Pearson Coefficient): {:.2f}'
      .format(skew(data_neg)))
print('Skewness (First Skewness Coefficient): {:.2f}'
      .format((mean - midpoint) / np.std(data_neg)))
sns.histplot(data_neg, bins='auto', kde=2)
plt.axvline(x=mean, color='r', linestyle='--', label='Mean')
plt.axvline(x=median, color='g', linestyle='-', label='Median')
plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')
plt.legend()
plt.show()

# Kurtosis: mesokurtic, platykurtic and leptokurtic distributions

import numpy as np
from scipy.stats import norm, laplace, semicircular
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as spy

# Normal distribution (Mesokurtic)
dnorm = norm.rvs(size=10000)
print(type(dnorm))
k = spy.kurtosis(dnorm)
print('Kurtosis: {:.2f}'.format(k))
sns.histplot(dnorm,bins='auto', kde = 2)
plt.title(f"Normal Distribution - Kurtosis: {k:.2f}")
plt.show()

# Uniform distribution (Platykurtic)
dunif = np.random.uniform(0.01, 0.10, 10000)
k = spy.kurtosis(dunif)
print('Kurtosis: {:.2f}'.format(k))
sns.histplot(dunif,bins='auto', kde = 2)
plt.title(f"Uniform Distribution - Kurtosis: {k:.2f}")
plt.show()

# Laplace distribution (Leptokurtic)
dlap = laplace.rvs(loc=0, scale=1, size=10000)
k = spy.kurtosis(dlap)
sns.histplot(dlap, bins='auto', kde = 2)
plt.title(f"Laplace Distribution - Kurtosis: {k:.2f}")
plt.show()

# Wigner semicircle distribution
dwigner = semicircular.rvs(size=10000)
k = spy.kurtosis(dwigner)
sns.histplot(dwigner, bins='auto', kde = 2)
plt.title(f"Wigner Semicircle Distribution - Kurtosis: {k:.2f}")
plt.show()

# Calculate the Skewness and Kurtosis for the Forest Fires variables

import pandas as pd

# load dataset
dforest = pd.read_csv("CO2 Emissions.csv")

# Skewness and kurtosis for each variable
skewness = dforest[['Fuel Consumption City (L/100 km)','Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)']].skew()
kurt = dforest[['Fuel Consumption City (L/100 km)','Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)']].kurtosis()

# Print the results and classify the kurtosis
for var in skewness.index:
    print(f"{var} Skewness: {skewness[var]:.2f}")
    if kurt[var] > 0:
        print(f"{var} Kurtosis: {kurt[var]:.2f} (Leptokurtic)")
    elif kurt[var] < 0:
        print(f"{var} Kurtosis: {kurt[var]:.2f} (Platykurtic)")
    else:
        print(f"{var} Kurtosis: {kurt[var]:.2f} (Mesokurtic)")

"""# The Normal Distribution"""

# Plot Normal Distributions

import numpy as np
import matplotlib.pyplot as plt

# Define an array of mean and standard deviation values
vmu = np.array([-1,0,1])
vsigma = np.array([.5,1,1.5])

# Create an array of x-values
x = np.linspace(-5,5,100)

# Loop through the mean and standard deviation values and plot the normal
# distributions
for mu,sigma in zip(vmu,vsigma):
    y = (1/(sigma*np.sqrt(2*np.pi))) * np.exp(-((x-mu)**2)/(2*sigma**2))
    plt.plot(x, y, label=f'={mu},={sigma}')

# Add a legend and axis labels
plt.legend()
plt.xlabel('x')
plt.ylabel('Probability density')
plt.title('Normal Distributions')
plt.show()

# Plot a Normal Distribution detaching  = {-3,-2,-1,0,1,2,3}

import numpy as np
import matplotlib.pyplot as plt

# Define the range of x values (which correspond to z-scores)
x = np.linspace(-4, 4, 1000)

# Calculate the probability density function (PDF) for the normal
# distribution
y = (1 / (np.sqrt(2 * np.pi))) * np.exp(-(x ** 2) / 2)

# Set up the plot, plot the PDF and vertical lines
fig, vax = plt.subplots()
vax.plot(x, y)
std = 1; mean = 0

for i in range(-3, 4):
    vax.axvline(mean + i * std, color='r', linestyle='--')

# Add a legend and labels to the plot
vax.set_xlabel("x")
vax.set_ylabel("PDF")
vax.set_title("Normal Distribution with Standard Deviation Lines")
plt.show()

"""# Measures of Association"""

# Calculate and print the Covariance Matrix of the Forest Fires dataset

import pandas as pd

# Load the dataset
dforest = pd.read_csv('CO2 Emissions.csv')

# Select the desired numeric features
features = ['Fuel Consumption City (L/100 km)','Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)']

# Compute the covariance matrix and format to two decimal places
pd.options.display.float_format = '{:.2f}'.format
Mcov = dforest[features].cov()

# Print the covariance matrix
print(Mcov)

# Calculate Correlation Coefficients: PCC, SRCC and KRCC
# for the numerical variables of the Forest Fires dataset

import pandas as pd

# Read the data into a pandas dataframe
dforest = pd.read_csv("CO2 Emissions.csv")
pd.options.display.float_format = '{:.2f}'.format

# Calculate PCC, SRCC, KRCC
print('**CO2 Emissions Dataset: PCC, SRCC, KRCC**')
PCC = dforest.corr(method='pearson')
print('Pearson Correlation Coefficient (PCC)\n',PCC)
SRCC = dforest.corr(method='spearman')
print('\nSpearman Rank Correlation Coefficient (SRCC)\n',SRCC)
KRCC = dforest.corr(method='kendall')
print('\nKramers Rank Correlation Coefficient (KRCC)\n',KRCC)

# Calculate Correlation Coefficients: Chi-square, Cramer's V and Point Biserial
# for the categorical variables of the Mammographic dataset
import pandas as pd
from scipy import stats
from scipy.stats import pointbiserialr

# Read the data from URL into a pandas dataframe
dforest = pd.read_csv("CO2 Emissions.csv")
dforest.dropna(inplace=True)  # Remove rows with missing values

# Chi-square and Cramer's V
cvars = ['Fuel Consumption City (L/100 km)','Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)', 'Fuel Consumption Comb (mpg)', 'CO2 Emissions(g/km)']
# Categorical variables
chis = pd.DataFrame()
phi = pd.DataFrame()
for var1 in cvars:
    for var2 in cvars:
        if var1 != var2:
            chi2, p, dof, ex = stats.chi2_contingency(pd.crosstab(dforest[var1], dforest[var2]))
            chis.loc[var1, var2] = chi2
            phi.loc[var1, var2] = np.sqrt(chi2 / (dforest.shape[0] * (min(ex.shape) - 1)))
print('\n**Mammographic Dataset: Chi-Square, Krammers V, PBCC**\n')
print('Chi-Square Correlation Coefficient (chi^2)\n',chis)
print('\nKramers V Correlation Coefficient (phi)\n',phi)

# Point Biserial Correlation between Age and Severity
PBCC, pval = stats.pointbiserialr(dforest['Fuel Consumption Comb (mpg)'], dforest['Fuel Type'])
print('\nPBCC between Age and Severity: {:.2f}'.format(PBCC))

# Scatter plots between pairs of variables from the Forest Fires dataset

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
dforest = pd.read_csv("CO2 Emissions.csv")

# Extract the relevant columns
cols = ['Make', 'Model', 'Vehicle Class', 'Engine Size(L)', 'Cylinders',
        'Transmission', 'Fuel Type', 'Fuel Consumption City (L/100 km)',
        'Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)',
        'Fuel Consumption Comb (mpg)','CO2 Emissions(g/km)']
dforest = dforest[cols]
df = dforest

# Generate the scatter plots
fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))
plt.subplots_adjust(wspace=0.4, hspace=0.4)
axs[0, 0].scatter(df['Engine Size(L)'], df['Fuel Consumption Comb (mpg)'], alpha=0.5)
axs[0, 0].set_xlabel('Engine Size(L)'); axs[0, 0].set_ylabel('Fuel Consumption Comb (mpg)')
axs[0, 0].set_title('PCC: {:.2f}'.format(df['Engine Size(L)'].corr(df['Fuel Consumption Comb (mpg)'], method='pearson')))

axs[0, 1].scatter(dforest['Engine Size(L)'], dforest['CO2 Emissions(g/km)'], alpha=0.5)
axs[0, 1].set_xlabel('Engine Size(L)'); axs[0, 1].set_ylabel('CO2 Emissions(g/km)')
axs[0, 1].set_title('PCC: {:.2f}'.format(df['Engine Size(L)'].corr(df['CO2 Emissions(g/km)'], method='pearson')))

axs[1, 0].scatter(dforest['Cylinders'], dforest['Fuel Consumption Comb (mpg)'], alpha=0.5)
axs[1, 0].set_xlabel('Cylinders'); axs[1, 0].set_ylabel('Fuel Consumption Comb (mpg)')
axs[1, 0].set_title('PCC: {:.2f}'.format(df['Cylinders'].corr(df['Fuel Consumption Comb (mpg)'], method='pearson')))

axs[1, 1].scatter(dforest['Cylinders'], dforest['CO2 Emissions(g/km)'], alpha=0.5)
axs[1, 1].set_xlabel('Cylinders'); axs[1, 1].set_ylabel('CO2 Emissions(g/km)')
axs[1, 1].set_title('PCC: {:.2f}'.format(df['Cylinders'].corr(df['CO2 Emissions(g/km)'], method='pearson')))

plt.show()

# Scatter plots between pairs of variables from the Forest Fires dataset

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
dforest = pd.read_csv("CO2 Emissions.csv")

# Extract the relevant columns
cols = ['Make', 'Model', 'Vehicle Class', 'Engine Size(L)', 'Cylinders',
        'Transmission', 'Fuel Type', 'Fuel Consumption City (L/100 km)',
        'Fuel Consumption Hwy (L/100 km)','Fuel Consumption Comb (L/100 km)',
        'Fuel Consumption Comb (mpg)','CO2 Emissions(g/km)']
dforest = dforest[cols]
df = dforest

# Generate the scatter plots
fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))
plt.subplots_adjust(wspace=0.4, hspace=0.4)
axs[0, 0].scatter(df['Engine Size(L)'], df['Fuel Consumption City (L/100 km)'], alpha=0.5)
axs[0, 0].set_xlabel('Engine Size(L)'); axs[0, 0].set_ylabel('Fuel Consumption City (L/100 km)')
axs[0, 0].set_title('PCC: {:.2f}'.format(df['Engine Size(L)'].corr(df['Fuel Consumption City (L/100 km)'], method='pearson')))

axs[0, 1].scatter(df['Engine Size(L)'], df['Fuel Consumption Hwy (L/100 km)'], alpha=0.5)
axs[0, 1].set_xlabel('Engine Size(L)'); axs[0, 1].set_ylabel('Fuel Consumption Hwy (L/100 km)')
axs[0, 1].set_title('PCC: {:.2f}'.format(df['Engine Size(L)'].corr(df['Fuel Consumption Hwy (L/100 km)'], method='pearson')))

axs[1, 0].scatter(dforest['Cylinders'], dforest['Fuel Consumption City (L/100 km)'], alpha=0.5)
axs[1, 0].set_xlabel('Cylinders'); axs[1, 0].set_ylabel('Fuel Consumption City (L/100 km)')
axs[1, 0].set_title('PCC: {:.2f}'.format(df['Cylinders'].corr(df['Fuel Consumption City (L/100 km)'], method='pearson')))

axs[1, 1].scatter(dforest['Cylinders'], dforest['Fuel Consumption Hwy (L/100 km)'], alpha=0.5)
axs[1, 1].set_xlabel('Cylinders'); axs[1, 1].set_ylabel('Fuel Consumption Hwy (L/100 km)')
axs[1, 1].set_title('PCC: {:.2f}'.format(df['Cylinders'].corr(df['Fuel Consumption Hwy (L/100 km)'], method='pearson')))

plt.show()